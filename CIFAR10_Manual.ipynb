{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10 Manual.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxk6sS4FKx7nTPv4v5j+pW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudiohfg/notebooks/blob/main/CIFAR10_Manual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB0UuHeuuYtk"
      },
      "source": [
        "# Load CIFAR-10 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl_75A_ulmAg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30387f45-64f2-46f7-b004-765737b208de"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sK3crZFlqh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e598c161-b512-4c72-b83e-47b70d1aae56"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-D_peuT1atH"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_html(\"https://www.cs.toronto.edu/~kriz/cifar.html\")\n",
        "cifar10_classes = df[0][0].values.tolist()\n",
        "cifar10_classes = dict(enumerate(cifar10_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9vygGwuud1L"
      },
      "source": [
        "# Load CIFAR-10 datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQb71-frBrRg"
      },
      "source": [
        "import tensorflow as tf\n",
        "(X_train, Y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9V-DJYnCrxs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2371c23b-e882-4875-eed9-2708531ae9df"
      },
      "source": [
        "X_train.shape, Y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nOpQIWeugk9"
      },
      "source": [
        "# Plot some CIFAR-10 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e2wHV2GJxIz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "d1477ebe-fb81-4f1a-f931-0b603e27d357"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "imagens = [np.random.randint(X_train.shape[0]) for x in range(4)]\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15, 4), constrained_layout=True)\n",
        "for ax, img in zip(axs, imagens):\n",
        "    ax.imshow(X_train[img])\n",
        "    ax.set_title(f\"{cifar10_classes[Y_train[img][0]]}\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7RO8H_Fuk8O"
      },
      "source": [
        "# One hot encode labels & standard scale data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz_kAn2uCwM1"
      },
      "source": [
        "Y_train = tf.keras.utils.to_categorical(Y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a54AuIu9u5jZ"
      },
      "source": [
        "# Z-score calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNAKZSs_FtnZ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "mean = np.mean(X_train, axis=(0,1,2,3))\n",
        "std = np.std(X_train, axis=(0,1,2,3))\n",
        "\n",
        "X_train = (X_train - mean)/(std + 1e-7)\n",
        "x_test = (x_test - mean)/(std + 1e-7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I3RLAHJu8Tp"
      },
      "source": [
        "# Train test split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0L4GCMliiQg"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    X_train, Y_train, test_size=0.3, random_state=42\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goaM2AX_u_iP"
      },
      "source": [
        "# ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKhRuSeP2ZO"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "BATCH_SIZE = 64\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaG4Hi_4wF-P"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMMWZL9TI5xQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0e7006f5-6568-40ef-9218-80d426bc1a1e"
      },
      "source": [
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.models as M\n",
        "import tensorflow.keras.optimizers as O\n",
        "\n",
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             input_shape=x_train.shape[1:]),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                327690    \n",
            "=================================================================\n",
            "Total params: 333,722\n",
            "Trainable params: 333,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfTUC9T9vhh5"
      },
      "source": [
        "model.compile(\n",
        "    'sgd', loss='mse', \n",
        "    metrics=[tf.keras.metrics.MeanSquaredError()]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Jc-wSDPtKv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "c3d70b77-7c74-4124-f09a-e9a63f28a6a6"
      },
      "source": [
        "EPOCHS = 20\n",
        "model.fit(\n",
        "    train_generator, steps_per_epoch=x_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.4735 - accuracy: 0.4827 - val_loss: 1.2010 - val_accuracy: 0.5832\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.0648 - accuracy: 0.6328 - val_loss: 1.1837 - val_accuracy: 0.5875\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.8500 - accuracy: 0.7111 - val_loss: 1.0994 - val_accuracy: 0.6231\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.6817 - accuracy: 0.7711 - val_loss: 1.1142 - val_accuracy: 0.6316\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.5260 - accuracy: 0.8261 - val_loss: 1.2168 - val_accuracy: 0.6247\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.3901 - accuracy: 0.8731 - val_loss: 1.3574 - val_accuracy: 0.6166\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.2725 - accuracy: 0.9120 - val_loss: 1.6097 - val_accuracy: 0.6129\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.1843 - accuracy: 0.9410 - val_loss: 1.8308 - val_accuracy: 0.6023\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.1228 - accuracy: 0.9606 - val_loss: 2.1309 - val_accuracy: 0.6014\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0837 - accuracy: 0.9745 - val_loss: 2.5383 - val_accuracy: 0.5980\n",
            "Epoch 11/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0587 - accuracy: 0.9817 - val_loss: 2.8350 - val_accuracy: 0.5945\n",
            "Epoch 12/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0468 - accuracy: 0.9848 - val_loss: 3.0111 - val_accuracy: 0.5955\n",
            "Epoch 13/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0353 - accuracy: 0.9886 - val_loss: 3.4128 - val_accuracy: 0.5981\n",
            "Epoch 14/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 3.5263 - val_accuracy: 0.5892\n",
            "Epoch 15/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0272 - accuracy: 0.9913 - val_loss: 4.0168 - val_accuracy: 0.5769\n",
            "Epoch 16/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 3.9898 - val_accuracy: 0.5885\n",
            "Epoch 17/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 4.1815 - val_accuracy: 0.5841\n",
            "Epoch 18/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 4.7691 - val_accuracy: 0.5771\n",
            "Epoch 19/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 4.7065 - val_accuracy: 0.5885\n",
            "Epoch 20/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 4.7958 - val_accuracy: 0.5886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc592641be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dor5Fgr8mb96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "cf4d3626-0a41-4cb1-ae2f-9767abf1391e"
      },
      "source": [
        "model.fit(\n",
        "    x_val, y_val, batch_size=BATCH_SIZE, \n",
        "    steps_per_epoch=x_val.shape[0]//BATCH_SIZE, epochs=EPOCHS, verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.9076 - accuracy: 0.5254\n",
            "Epoch 2/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0177 - accuracy: 0.6596\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.7704\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.4377 - accuracy: 0.8616\n",
            "Epoch 5/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.2589 - accuracy: 0.9239\n",
            "Epoch 6/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.1336 - accuracy: 0.9662\n",
            "Epoch 7/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9861\n",
            "Epoch 8/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9942\n",
            "Epoch 9/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9977\n",
            "Epoch 10/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9983\n",
            "Epoch 11/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9989\n",
            "Epoch 12/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 13/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 14/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 15/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 9.1435e-04 - accuracy: 0.9998\n",
            "Epoch 16/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 7.1350e-04 - accuracy: 0.9998\n",
            "Epoch 17/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 8.6089e-04 - accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 9.8982e-04 - accuracy: 0.9998\n",
            "Epoch 19/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9997\n",
            "Epoch 20/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 8.8642e-04 - accuracy: 0.9997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4d26299b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0suYS-G3lzol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c20a6ca-2f8a-4045-faed-c250388831b5"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 58.630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8iRFIBNxZXJ"
      },
      "source": [
        "# Model 2: more convolutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niNQOBdGP9Vo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ae0dd37f-4c3d-4fad-de29-29031adedb19"
      },
      "source": [
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             input_shape=x_train.shape[1:]),\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 32, 32, 16)        2320      \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                327690    \n",
            "=================================================================\n",
            "Total params: 345,874\n",
            "Trainable params: 345,874\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn5cZ2oIkMgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "cfafd5a5-71fa-4aeb-cedf-be123102e257"
      },
      "source": [
        "model.fit(\n",
        "    train_generator, steps_per_epoch=x_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 5s 10ms/step - loss: 1.6067 - accuracy: 0.4318 - val_loss: 1.2979 - val_accuracy: 0.5351\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.1920 - accuracy: 0.5806 - val_loss: 1.2715 - val_accuracy: 0.5630\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.0025 - accuracy: 0.6508 - val_loss: 1.2321 - val_accuracy: 0.5758\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.8538 - accuracy: 0.7041 - val_loss: 1.0823 - val_accuracy: 0.6240\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.7286 - accuracy: 0.7518 - val_loss: 1.1098 - val_accuracy: 0.6313\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.5917 - accuracy: 0.7992 - val_loss: 1.1373 - val_accuracy: 0.6347\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.4715 - accuracy: 0.8419 - val_loss: 1.3485 - val_accuracy: 0.6138\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 5s 10ms/step - loss: 0.3605 - accuracy: 0.8783 - val_loss: 1.4454 - val_accuracy: 0.6279\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.2658 - accuracy: 0.9112 - val_loss: 1.7696 - val_accuracy: 0.6119\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.1891 - accuracy: 0.9369 - val_loss: 1.9029 - val_accuracy: 0.6049\n",
            "Epoch 11/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.1391 - accuracy: 0.9538 - val_loss: 2.2351 - val_accuracy: 0.6068\n",
            "Epoch 12/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.1042 - accuracy: 0.9647 - val_loss: 2.7985 - val_accuracy: 0.5982\n",
            "Epoch 13/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0835 - accuracy: 0.9721 - val_loss: 2.9022 - val_accuracy: 0.6070\n",
            "Epoch 14/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0723 - accuracy: 0.9761 - val_loss: 3.5112 - val_accuracy: 0.5962\n",
            "Epoch 15/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0650 - accuracy: 0.9791 - val_loss: 3.5400 - val_accuracy: 0.5937\n",
            "Epoch 16/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 3.7823 - val_accuracy: 0.5971\n",
            "Epoch 17/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 4.0883 - val_accuracy: 0.6045\n",
            "Epoch 18/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0568 - accuracy: 0.9819 - val_loss: 4.3271 - val_accuracy: 0.5985\n",
            "Epoch 19/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0520 - accuracy: 0.9832 - val_loss: 4.2772 - val_accuracy: 0.5998\n",
            "Epoch 20/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 4.6905 - val_accuracy: 0.5991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4d2500588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pac9JrEomuov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "1e81efc0-73b7-45b7-cf63-59c2093b241b"
      },
      "source": [
        "model.fit(\n",
        "    x_val, y_val, batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=x_val.shape[0]//BATCH_SIZE, epochs=EPOCHS, verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 1.4058 - accuracy: 0.5702\n",
            "Epoch 2/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.8931 - accuracy: 0.6918\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.6371 - accuracy: 0.7825\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.4353 - accuracy: 0.8600\n",
            "Epoch 5/20\n",
            "234/234 [==============================] - 2s 7ms/step - loss: 0.2630 - accuracy: 0.9189\n",
            "Epoch 6/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.1411 - accuracy: 0.9586\n",
            "Epoch 7/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0719 - accuracy: 0.9796\n",
            "Epoch 8/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0407 - accuracy: 0.9888\n",
            "Epoch 9/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0246 - accuracy: 0.9921\n",
            "Epoch 10/20\n",
            "234/234 [==============================] - 2s 7ms/step - loss: 0.0177 - accuracy: 0.9946\n",
            "Epoch 11/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0185 - accuracy: 0.9934\n",
            "Epoch 12/20\n",
            "234/234 [==============================] - 2s 7ms/step - loss: 0.0150 - accuracy: 0.9952\n",
            "Epoch 13/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0173 - accuracy: 0.9946\n",
            "Epoch 14/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0108 - accuracy: 0.9968\n",
            "Epoch 15/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0129 - accuracy: 0.9960\n",
            "Epoch 16/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0116 - accuracy: 0.9962\n",
            "Epoch 17/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9958\n",
            "Epoch 18/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0164 - accuracy: 0.9944\n",
            "Epoch 19/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9963\n",
            "Epoch 20/20\n",
            "234/234 [==============================] - 2s 6ms/step - loss: 0.0154 - accuracy: 0.9957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4d22899e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqpOlCeVl1H0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2b1cf67-1504-4e8f-e48f-d49824a5017a"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 59.890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmGaaHWGxbHI"
      },
      "source": [
        "# Model 3: max pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM3UMErBkNAd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "9796fe81-2cd6-4e98-87a4-87ad4026747f"
      },
      "source": [
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             input_shape=x_train.shape[1:]),\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    \n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 16, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 23,314\n",
            "Trainable params: 23,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5HjVHQdle9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "0a178c64-9dff-4f01-af1c-670fe503b3fd"
      },
      "source": [
        "model.fit(\n",
        "    train_generator, steps_per_epoch=x_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 4s 8ms/step - loss: 1.7361 - accuracy: 0.3671 - val_loss: 1.4826 - val_accuracy: 0.4656\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.4213 - accuracy: 0.4896 - val_loss: 1.3302 - val_accuracy: 0.5181\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.2757 - accuracy: 0.5443 - val_loss: 1.2264 - val_accuracy: 0.5646\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.1666 - accuracy: 0.5823 - val_loss: 1.1433 - val_accuracy: 0.5922\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.0820 - accuracy: 0.6174 - val_loss: 1.0674 - val_accuracy: 0.6244\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 1.0194 - accuracy: 0.6417 - val_loss: 1.1135 - val_accuracy: 0.6128\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.9605 - accuracy: 0.6621 - val_loss: 0.9960 - val_accuracy: 0.6530\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.9190 - accuracy: 0.6776 - val_loss: 0.9743 - val_accuracy: 0.6645\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.8828 - accuracy: 0.6915 - val_loss: 0.9930 - val_accuracy: 0.6527\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.8402 - accuracy: 0.7046 - val_loss: 0.9628 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.8173 - accuracy: 0.7137 - val_loss: 0.9953 - val_accuracy: 0.6572\n",
            "Epoch 12/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.7792 - accuracy: 0.7262 - val_loss: 0.9947 - val_accuracy: 0.6593\n",
            "Epoch 13/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.7607 - accuracy: 0.7344 - val_loss: 0.9430 - val_accuracy: 0.6757\n",
            "Epoch 14/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.7364 - accuracy: 0.7425 - val_loss: 0.9767 - val_accuracy: 0.6716\n",
            "Epoch 15/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.7127 - accuracy: 0.7484 - val_loss: 0.9563 - val_accuracy: 0.6783\n",
            "Epoch 16/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.6917 - accuracy: 0.7580 - val_loss: 0.9344 - val_accuracy: 0.6821\n",
            "Epoch 17/20\n",
            "546/546 [==============================] - 4s 7ms/step - loss: 0.6761 - accuracy: 0.7657 - val_loss: 0.9536 - val_accuracy: 0.6823\n",
            "Epoch 18/20\n",
            "546/546 [==============================] - 4s 8ms/step - loss: 0.6602 - accuracy: 0.7674 - val_loss: 0.9658 - val_accuracy: 0.6815\n",
            "Epoch 19/20\n",
            "546/546 [==============================] - 4s 8ms/step - loss: 0.6376 - accuracy: 0.7782 - val_loss: 0.9291 - val_accuracy: 0.6891\n",
            "Epoch 20/20\n",
            "546/546 [==============================] - 4s 8ms/step - loss: 0.6250 - accuracy: 0.7818 - val_loss: 0.9356 - val_accuracy: 0.6939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4d2334940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkBx5vAwmwVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "5b26055e-64b6-44db-9c28-ff9568859199"
      },
      "source": [
        "model.fit(\n",
        "    x_val, y_val, batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=x_val.shape[0]//BATCH_SIZE, epochs=EPOCHS, verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 0.9293 - accuracy: 0.6810\n",
            "Epoch 2/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.8267 - accuracy: 0.7125\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.7726 - accuracy: 0.7296\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.7183 - accuracy: 0.7485\n",
            "Epoch 5/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.7624\n",
            "Epoch 6/20\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 0.6341 - accuracy: 0.7809\n",
            "Epoch 7/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.5989 - accuracy: 0.7922\n",
            "Epoch 8/20\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.8045\n",
            "Epoch 9/20\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 0.5321 - accuracy: 0.8145\n",
            "Epoch 10/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.8261\n",
            "Epoch 11/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.4775 - accuracy: 0.8348\n",
            "Epoch 12/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.4468 - accuracy: 0.8449\n",
            "Epoch 13/20\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8557\n",
            "Epoch 14/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.4018 - accuracy: 0.8626\n",
            "Epoch 15/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.3704 - accuracy: 0.8739\n",
            "Epoch 16/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.3524 - accuracy: 0.8788\n",
            "Epoch 17/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.8848\n",
            "Epoch 18/20\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 0.3115 - accuracy: 0.8931\n",
            "Epoch 19/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.2933 - accuracy: 0.9004\n",
            "Epoch 20/20\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.2801 - accuracy: 0.9018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4b877b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVkKwN9olfiB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23323794-188e-4a24-aef1-9227a42d3bc5"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 66.440\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gWckhhuxcsk"
      },
      "source": [
        "# Model 4: batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpnycrvVnUiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "de69d9b8-5604-4802-d4ca-9b9f9e73856e"
      },
      "source": [
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             input_shape=x_train.shape[1:]),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    \n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 16, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 23,762\n",
            "Trainable params: 23,538\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IjQXXBGoScW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "1e092fad-f47d-4f65-a49c-1bfaba6cb5f1"
      },
      "source": [
        "model.fit(\n",
        "    train_generator, steps_per_epoch=x_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.6201 - accuracy: 0.4341 - val_loss: 1.3383 - val_accuracy: 0.5259\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 1.1916 - accuracy: 0.5763 - val_loss: 1.1304 - val_accuracy: 0.5947\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 1.0375 - accuracy: 0.6317 - val_loss: 1.0447 - val_accuracy: 0.6316\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.9312 - accuracy: 0.6708 - val_loss: 1.0135 - val_accuracy: 0.6493\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.8507 - accuracy: 0.7021 - val_loss: 0.9387 - val_accuracy: 0.6784\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.7942 - accuracy: 0.7229 - val_loss: 0.9197 - val_accuracy: 0.6839\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.7428 - accuracy: 0.7398 - val_loss: 0.9085 - val_accuracy: 0.6897\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.7090 - accuracy: 0.7511 - val_loss: 0.8980 - val_accuracy: 0.6940\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.6730 - accuracy: 0.7643 - val_loss: 0.9092 - val_accuracy: 0.6914\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.6439 - accuracy: 0.7757 - val_loss: 0.9225 - val_accuracy: 0.6980\n",
            "Epoch 11/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.6188 - accuracy: 0.7842 - val_loss: 0.9109 - val_accuracy: 0.7002\n",
            "Epoch 12/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.5938 - accuracy: 0.7921 - val_loss: 0.9455 - val_accuracy: 0.6921\n",
            "Epoch 13/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.5644 - accuracy: 0.8024 - val_loss: 0.9339 - val_accuracy: 0.7019\n",
            "Epoch 14/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.5482 - accuracy: 0.8078 - val_loss: 0.9117 - val_accuracy: 0.7060\n",
            "Epoch 15/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.5311 - accuracy: 0.8135 - val_loss: 0.9530 - val_accuracy: 0.7042\n",
            "Epoch 16/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.5077 - accuracy: 0.8204 - val_loss: 1.0322 - val_accuracy: 0.6899\n",
            "Epoch 17/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.4961 - accuracy: 0.8246 - val_loss: 0.9806 - val_accuracy: 0.6972\n",
            "Epoch 18/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.4767 - accuracy: 0.8298 - val_loss: 1.0197 - val_accuracy: 0.6958\n",
            "Epoch 19/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.4629 - accuracy: 0.8355 - val_loss: 1.0098 - val_accuracy: 0.6991\n",
            "Epoch 20/20\n",
            "546/546 [==============================] - 5s 8ms/step - loss: 0.4447 - accuracy: 0.8420 - val_loss: 1.0498 - val_accuracy: 0.6999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4b8792518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1ZCkW2koTFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "5c8f796c-5c5b-4b29-db18-5f9e7e3252df"
      },
      "source": [
        "model.fit(\n",
        "    x_val, y_val, batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=x_val.shape[0]//BATCH_SIZE, epochs=EPOCHS, verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.9751 - accuracy: 0.6972\n",
            "Epoch 2/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7625 - accuracy: 0.7396\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.6705 - accuracy: 0.7687\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.6043 - accuracy: 0.7894\n",
            "Epoch 5/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.5510 - accuracy: 0.8077\n",
            "Epoch 6/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.5071 - accuracy: 0.8212\n",
            "Epoch 7/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.4616 - accuracy: 0.8405\n",
            "Epoch 8/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.4261 - accuracy: 0.8512\n",
            "Epoch 9/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.3904 - accuracy: 0.8651\n",
            "Epoch 10/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.3636 - accuracy: 0.8735\n",
            "Epoch 11/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.3313 - accuracy: 0.8875\n",
            "Epoch 12/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.3044 - accuracy: 0.8964\n",
            "Epoch 13/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.2816 - accuracy: 0.9056\n",
            "Epoch 14/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.2569 - accuracy: 0.9095\n",
            "Epoch 15/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.2362 - accuracy: 0.9214\n",
            "Epoch 16/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.2183 - accuracy: 0.9255\n",
            "Epoch 17/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.1987 - accuracy: 0.9315\n",
            "Epoch 18/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9384\n",
            "Epoch 19/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.1760 - accuracy: 0.9401\n",
            "Epoch 20/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.1613 - accuracy: 0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4b8163ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgz7HFdPoVYi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3d01ba5-ec02-404a-aa39-74efc8357dc8"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 68.060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6TXm2G3xhSU"
      },
      "source": [
        "# Model 5: regularization & dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgVIgP_GoXiT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "fe08cd4f-7814-4fd8-e3b2-1a7b0075d856"
      },
      "source": [
        "import tensorflow.keras.regularizers as R\n",
        "\n",
        "WEIGHT_DECAY = 1e-4\n",
        "L2 = R.l2(WEIGHT_DECAY)\n",
        "\n",
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2, input_shape=x_train.shape[1:]),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.2),\n",
        "\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.3),\n",
        "\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.4),\n",
        "    \n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_42 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 16, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 23,762\n",
            "Trainable params: 23,538\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQpJ3g8IozSR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "a2894b40-d606-435c-93bb-5fb609448068"
      },
      "source": [
        "model.fit(\n",
        "    train_generator, steps_per_epoch=x_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS, validation_data=(x_val, y_val), verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 2.0812 - accuracy: 0.3348 - val_loss: 1.3782 - val_accuracy: 0.4987\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.4335 - accuracy: 0.4860 - val_loss: 1.2645 - val_accuracy: 0.5476\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.2775 - accuracy: 0.5470 - val_loss: 1.0968 - val_accuracy: 0.6142\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.1869 - accuracy: 0.5821 - val_loss: 1.0080 - val_accuracy: 0.6468\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.1274 - accuracy: 0.6046 - val_loss: 0.9790 - val_accuracy: 0.6580\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.0783 - accuracy: 0.6212 - val_loss: 1.0258 - val_accuracy: 0.6386\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.0479 - accuracy: 0.6344 - val_loss: 0.9508 - val_accuracy: 0.6676\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.0201 - accuracy: 0.6429 - val_loss: 0.9325 - val_accuracy: 0.6757\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 1.0058 - accuracy: 0.6508 - val_loss: 0.8921 - val_accuracy: 0.6867\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9781 - accuracy: 0.6605 - val_loss: 0.8887 - val_accuracy: 0.6923\n",
            "Epoch 11/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9672 - accuracy: 0.6670 - val_loss: 0.8923 - val_accuracy: 0.6859\n",
            "Epoch 12/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9458 - accuracy: 0.6726 - val_loss: 0.8653 - val_accuracy: 0.6989\n",
            "Epoch 13/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9380 - accuracy: 0.6739 - val_loss: 0.8379 - val_accuracy: 0.7089\n",
            "Epoch 14/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9234 - accuracy: 0.6839 - val_loss: 0.8668 - val_accuracy: 0.7005\n",
            "Epoch 15/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9157 - accuracy: 0.6863 - val_loss: 0.8273 - val_accuracy: 0.7131\n",
            "Epoch 16/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.9046 - accuracy: 0.6859 - val_loss: 0.8241 - val_accuracy: 0.7133\n",
            "Epoch 17/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.8985 - accuracy: 0.6906 - val_loss: 0.8208 - val_accuracy: 0.7155\n",
            "Epoch 18/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.8874 - accuracy: 0.6952 - val_loss: 0.7932 - val_accuracy: 0.7249\n",
            "Epoch 19/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.8816 - accuracy: 0.6955 - val_loss: 0.7863 - val_accuracy: 0.7269\n",
            "Epoch 20/20\n",
            "546/546 [==============================] - 5s 9ms/step - loss: 0.8686 - accuracy: 0.7007 - val_loss: 0.7840 - val_accuracy: 0.7321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4a477ccc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRR40gsBpFVP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "481597d4-1851-4d36-ff04-5d642ad82e40"
      },
      "source": [
        "model.fit(\n",
        "    x_val, y_val, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    steps_per_epoch=x_val.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS,  \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.9225 - accuracy: 0.6843\n",
            "Epoch 2/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.9009 - accuracy: 0.6891\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8779 - accuracy: 0.6988\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8662 - accuracy: 0.7006\n",
            "Epoch 5/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8586 - accuracy: 0.7051\n",
            "Epoch 6/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8527 - accuracy: 0.7069\n",
            "Epoch 7/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8399 - accuracy: 0.7067\n",
            "Epoch 8/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8237 - accuracy: 0.7153\n",
            "Epoch 9/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8255 - accuracy: 0.7186\n",
            "Epoch 10/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8251 - accuracy: 0.7146\n",
            "Epoch 11/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8070 - accuracy: 0.7170\n",
            "Epoch 12/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8084 - accuracy: 0.7238\n",
            "Epoch 13/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8028 - accuracy: 0.7250\n",
            "Epoch 14/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.8053 - accuracy: 0.7212\n",
            "Epoch 15/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7824 - accuracy: 0.7306\n",
            "Epoch 16/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7822 - accuracy: 0.7306\n",
            "Epoch 17/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7850 - accuracy: 0.7300\n",
            "Epoch 18/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7852 - accuracy: 0.7317\n",
            "Epoch 19/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7680 - accuracy: 0.7401\n",
            "Epoch 20/20\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 0.7772 - accuracy: 0.7379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4a2272b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prQeDZqYpHEh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "453e3dbe-de4e-429e-fd38-f71ccd4cd5e3"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 73.610\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tevrXS-cx12h"
      },
      "source": [
        "# Model 6: data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8OJJyh5pH1P"
      },
      "source": [
        "import tensorflow.keras.preprocessing.image as I\n",
        "\n",
        "train_datagen = I.ImageDataGenerator(\n",
        "    width_shift_range=0.1, height_shift_range=0.1,\n",
        "    horizontal_flip=True, rotation_range=15\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(x_train, y_train, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUJpDue0p59z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "60697af2-bea1-454f-bd6f-6beebf21ce94"
      },
      "source": [
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2, input_shape=x_train.shape[1:]),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.2),\n",
        "\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.3),\n",
        "\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.4),\n",
        "    \n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_48 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 16, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 23,762\n",
            "Trainable params: 23,538\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5suwU4HirnMn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "cd5c2974-6f70-401b-c686-8adb9c09edd7"
      },
      "source": [
        "model.fit(\n",
        "    train_generator, \n",
        "    steps_per_epoch=x_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS,  \n",
        "    validation_data=(x_val, y_val), \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 2.1521 - accuracy: 0.3102 - val_loss: 1.4999 - val_accuracy: 0.4549\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 18s 32ms/step - loss: 1.5614 - accuracy: 0.4364 - val_loss: 1.3682 - val_accuracy: 0.5011\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.4061 - accuracy: 0.4969 - val_loss: 1.3313 - val_accuracy: 0.5179\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.3163 - accuracy: 0.5343 - val_loss: 1.1929 - val_accuracy: 0.5725\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.2531 - accuracy: 0.5578 - val_loss: 1.1622 - val_accuracy: 0.5916\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.2053 - accuracy: 0.5747 - val_loss: 1.1256 - val_accuracy: 0.6047\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.1729 - accuracy: 0.5890 - val_loss: 1.1454 - val_accuracy: 0.6030\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.1431 - accuracy: 0.6012 - val_loss: 1.0575 - val_accuracy: 0.6309\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.1192 - accuracy: 0.6080 - val_loss: 1.0268 - val_accuracy: 0.6442\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0950 - accuracy: 0.6153 - val_loss: 0.9796 - val_accuracy: 0.6624\n",
            "Epoch 11/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0802 - accuracy: 0.6219 - val_loss: 1.0278 - val_accuracy: 0.6456\n",
            "Epoch 12/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0632 - accuracy: 0.6316 - val_loss: 0.9473 - val_accuracy: 0.6689\n",
            "Epoch 13/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0496 - accuracy: 0.6332 - val_loss: 0.9867 - val_accuracy: 0.6614\n",
            "Epoch 14/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0407 - accuracy: 0.6408 - val_loss: 0.9629 - val_accuracy: 0.6703\n",
            "Epoch 15/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0278 - accuracy: 0.6431 - val_loss: 0.9445 - val_accuracy: 0.6726\n",
            "Epoch 16/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0256 - accuracy: 0.6447 - val_loss: 0.9287 - val_accuracy: 0.6827\n",
            "Epoch 17/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0085 - accuracy: 0.6508 - val_loss: 0.9510 - val_accuracy: 0.6797\n",
            "Epoch 18/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 1.0040 - accuracy: 0.6515 - val_loss: 0.8787 - val_accuracy: 0.6965\n",
            "Epoch 19/20\n",
            "546/546 [==============================] - 17s 31ms/step - loss: 0.9983 - accuracy: 0.6541 - val_loss: 0.9495 - val_accuracy: 0.6731\n",
            "Epoch 20/20\n",
            "546/546 [==============================] - 18s 32ms/step - loss: 0.9861 - accuracy: 0.6616 - val_loss: 0.9007 - val_accuracy: 0.6953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4a2a63be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHDt2gIJsPEM"
      },
      "source": [
        "train_generator = train_datagen.flow(x_val, y_val, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2npTuUyrobI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "e3351120-2b3c-457d-9dee-6b7bc42811de"
      },
      "source": [
        "model.fit(\n",
        "    train_generator, \n",
        "    steps_per_epoch=x_val.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS,  \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9874 - accuracy: 0.6613\n",
            "Epoch 2/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9885 - accuracy: 0.6603\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9838 - accuracy: 0.6631\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9714 - accuracy: 0.6643\n",
            "Epoch 5/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9740 - accuracy: 0.6633\n",
            "Epoch 6/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9647 - accuracy: 0.6704\n",
            "Epoch 7/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9720 - accuracy: 0.6675\n",
            "Epoch 8/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9587 - accuracy: 0.6722\n",
            "Epoch 9/20\n",
            "234/234 [==============================] - 7s 30ms/step - loss: 0.9665 - accuracy: 0.6654\n",
            "Epoch 10/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9521 - accuracy: 0.6726\n",
            "Epoch 11/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9550 - accuracy: 0.6722\n",
            "Epoch 12/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9503 - accuracy: 0.6725\n",
            "Epoch 13/20\n",
            "234/234 [==============================] - 7s 30ms/step - loss: 0.9569 - accuracy: 0.6743\n",
            "Epoch 14/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9530 - accuracy: 0.6713\n",
            "Epoch 15/20\n",
            "234/234 [==============================] - 7s 28ms/step - loss: 0.9482 - accuracy: 0.6698\n",
            "Epoch 16/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9386 - accuracy: 0.6793\n",
            "Epoch 17/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9430 - accuracy: 0.6780\n",
            "Epoch 18/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9424 - accuracy: 0.6790\n",
            "Epoch 19/20\n",
            "234/234 [==============================] - 7s 29ms/step - loss: 0.9386 - accuracy: 0.6762\n",
            "Epoch 20/20\n",
            "234/234 [==============================] - 7s 28ms/step - loss: 0.9420 - accuracy: 0.6761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4a2a63940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0xdwE4fqEB0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82de6e84-eaa9-4e8f-fdc3-115a2c1030db"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 70.780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2C5HwuAx7YV"
      },
      "source": [
        "# Model 7: callback functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10dF4TCJOMua"
      },
      "source": [
        "import tensorflow.keras.callbacks as C\n",
        "\n",
        "reduce_learning_rate = C.ReduceLROnPlateau(\n",
        "    monitor='loss', factor=0.5, patience=5, verbose=1, \n",
        "    mode='auto', min_delta=1e-5, cooldown=0, min_lr=0\n",
        ")\n",
        "\n",
        "early_stopping = C.EarlyStopping(\n",
        "    monitor='loss', min_delta=0, patience=12, verbose=1, mode='auto',\n",
        "    baseline=None, restore_best_weights=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaxZvf7cv7V8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "1413a2bb-2905-4518-e335-ca9eb296842a"
      },
      "source": [
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2, input_shape=x_train.shape[1:]),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=8, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.2),\n",
        "\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.3),\n",
        "\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.4),\n",
        "    \n",
        "    L.Flatten(),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_54 (Conv2D)           (None, 32, 32, 8)         224       \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 32, 32, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 32, 32, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 16, 16, 16)        1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 16, 16, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 16, 16, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 8, 8, 32)          9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 8, 8, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 23,762\n",
            "Trainable params: 23,538\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYLJ3Dx9ImFv"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=15\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwmE02bvALUR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2174801-b5c8-4fe2-99a9-f70f8319e7fc"
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "model.fit(\n",
        "    train_generator, \n",
        "    steps_per_epoch=X_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS,  \n",
        "    callbacks=[reduce_learning_rate, early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 2.0029 - accuracy: 0.3394 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 1.4690 - accuracy: 0.4732 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 1.3247 - accuracy: 0.5266 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "781/781 [==============================] - 32s 40ms/step - loss: 1.2520 - accuracy: 0.5548 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 1.1979 - accuracy: 0.5793 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 1.1618 - accuracy: 0.5897 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "781/781 [==============================] - 32s 40ms/step - loss: 1.1321 - accuracy: 0.6043 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "781/781 [==============================] - 32s 40ms/step - loss: 1.1113 - accuracy: 0.6117 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 1.0832 - accuracy: 0.6235 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 1.0685 - accuracy: 0.6239 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 1.0530 - accuracy: 0.6343 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 1.0334 - accuracy: 0.6422 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 1.0308 - accuracy: 0.6419 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 1.0135 - accuracy: 0.6502 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 1.0103 - accuracy: 0.6492 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9978 - accuracy: 0.6568 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9935 - accuracy: 0.6583 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9868 - accuracy: 0.6609 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9792 - accuracy: 0.6626 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.9742 - accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9706 - accuracy: 0.6674 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9645 - accuracy: 0.6684 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9640 - accuracy: 0.6694 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9574 - accuracy: 0.6717 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9500 - accuracy: 0.6770 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9556 - accuracy: 0.6716 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9451 - accuracy: 0.6763 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9461 - accuracy: 0.6768 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9393 - accuracy: 0.6788 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9384 - accuracy: 0.6784 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9331 - accuracy: 0.6808 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.9342 - accuracy: 0.6797 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9345 - accuracy: 0.6791 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9233 - accuracy: 0.6868 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9274 - accuracy: 0.6839 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.9242 - accuracy: 0.6849 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9262 - accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9238 - accuracy: 0.6847 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.9248 - accuracy: 0.6867\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9246 - accuracy: 0.6867 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8962 - accuracy: 0.6965 - lr: 5.0000e-04\n",
            "Epoch 41/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8957 - accuracy: 0.6948 - lr: 5.0000e-04\n",
            "Epoch 42/1000\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.8935 - accuracy: 0.6972 - lr: 5.0000e-04\n",
            "Epoch 43/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8851 - accuracy: 0.6998 - lr: 5.0000e-04\n",
            "Epoch 44/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8903 - accuracy: 0.6981 - lr: 5.0000e-04\n",
            "Epoch 45/1000\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.8893 - accuracy: 0.6986 - lr: 5.0000e-04\n",
            "Epoch 46/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8829 - accuracy: 0.7015 - lr: 5.0000e-04\n",
            "Epoch 47/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8877 - accuracy: 0.6969 - lr: 5.0000e-04\n",
            "Epoch 48/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8810 - accuracy: 0.7028 - lr: 5.0000e-04\n",
            "Epoch 49/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8795 - accuracy: 0.7003 - lr: 5.0000e-04\n",
            "Epoch 50/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8780 - accuracy: 0.7020 - lr: 5.0000e-04\n",
            "Epoch 51/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8775 - accuracy: 0.7031 - lr: 5.0000e-04\n",
            "Epoch 52/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8762 - accuracy: 0.7023 - lr: 5.0000e-04\n",
            "Epoch 53/1000\n",
            "781/781 [==============================] - 32s 40ms/step - loss: 0.8832 - accuracy: 0.7001 - lr: 5.0000e-04\n",
            "Epoch 54/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8751 - accuracy: 0.7057 - lr: 5.0000e-04\n",
            "Epoch 55/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8778 - accuracy: 0.7010 - lr: 5.0000e-04\n",
            "Epoch 56/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8794 - accuracy: 0.7027 - lr: 5.0000e-04\n",
            "Epoch 57/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8736 - accuracy: 0.7039 - lr: 5.0000e-04\n",
            "Epoch 58/1000\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.8767 - accuracy: 0.7030 - lr: 5.0000e-04\n",
            "Epoch 59/1000\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.8683 - accuracy: 0.7070 - lr: 5.0000e-04\n",
            "Epoch 60/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8671 - accuracy: 0.7070 - lr: 5.0000e-04\n",
            "Epoch 61/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8698 - accuracy: 0.7060 - lr: 5.0000e-04\n",
            "Epoch 62/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8712 - accuracy: 0.7036 - lr: 5.0000e-04\n",
            "Epoch 63/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8685 - accuracy: 0.7042 - lr: 5.0000e-04\n",
            "Epoch 64/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8712 - accuracy: 0.7038 - lr: 5.0000e-04\n",
            "Epoch 65/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8729 - accuracy: 0.7043\n",
            "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8729 - accuracy: 0.7043 - lr: 5.0000e-04\n",
            "Epoch 66/1000\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.8576 - accuracy: 0.7091 - lr: 2.5000e-04\n",
            "Epoch 67/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8569 - accuracy: 0.7113 - lr: 2.5000e-04\n",
            "Epoch 68/1000\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.8522 - accuracy: 0.7094 - lr: 2.5000e-04\n",
            "Epoch 69/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8537 - accuracy: 0.7105 - lr: 2.5000e-04\n",
            "Epoch 70/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8499 - accuracy: 0.7125 - lr: 2.5000e-04\n",
            "Epoch 71/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8507 - accuracy: 0.7114 - lr: 2.5000e-04\n",
            "Epoch 72/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8553 - accuracy: 0.7110 - lr: 2.5000e-04\n",
            "Epoch 73/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8472 - accuracy: 0.7131 - lr: 2.5000e-04\n",
            "Epoch 74/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8525 - accuracy: 0.7112 - lr: 2.5000e-04\n",
            "Epoch 75/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8565 - accuracy: 0.7080 - lr: 2.5000e-04\n",
            "Epoch 76/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8485 - accuracy: 0.7128 - lr: 2.5000e-04\n",
            "Epoch 77/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8488 - accuracy: 0.7112 - lr: 2.5000e-04\n",
            "Epoch 78/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.8526 - accuracy: 0.7094\n",
            "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8526 - accuracy: 0.7095 - lr: 2.5000e-04\n",
            "Epoch 79/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8376 - accuracy: 0.7147 - lr: 1.2500e-04\n",
            "Epoch 80/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8485 - accuracy: 0.7120 - lr: 1.2500e-04\n",
            "Epoch 81/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8405 - accuracy: 0.7128 - lr: 1.2500e-04\n",
            "Epoch 82/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8362 - accuracy: 0.7171 - lr: 1.2500e-04\n",
            "Epoch 83/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8341 - accuracy: 0.7174 - lr: 1.2500e-04\n",
            "Epoch 84/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8441 - accuracy: 0.7126 - lr: 1.2500e-04\n",
            "Epoch 85/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8403 - accuracy: 0.7141 - lr: 1.2500e-04\n",
            "Epoch 86/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8385 - accuracy: 0.7152 - lr: 1.2500e-04\n",
            "Epoch 87/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8342 - accuracy: 0.7146 - lr: 1.2500e-04\n",
            "Epoch 88/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.7146\n",
            "Epoch 00088: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8391 - accuracy: 0.7146 - lr: 1.2500e-04\n",
            "Epoch 89/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8407 - accuracy: 0.7154 - lr: 6.2500e-05\n",
            "Epoch 90/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8338 - accuracy: 0.7157 - lr: 6.2500e-05\n",
            "Epoch 91/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8288 - accuracy: 0.7212 - lr: 6.2500e-05\n",
            "Epoch 92/1000\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8283 - accuracy: 0.7179 - lr: 6.2500e-05\n",
            "Epoch 93/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8378 - accuracy: 0.7142 - lr: 6.2500e-05\n",
            "Epoch 94/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8313 - accuracy: 0.7181 - lr: 6.2500e-05\n",
            "Epoch 95/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8292 - accuracy: 0.7184 - lr: 6.2500e-05\n",
            "Epoch 96/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8276 - accuracy: 0.7196 - lr: 6.2500e-05\n",
            "Epoch 97/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8352 - accuracy: 0.7162 - lr: 6.2500e-05\n",
            "Epoch 98/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8329 - accuracy: 0.7180 - lr: 6.2500e-05\n",
            "Epoch 99/1000\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8345 - accuracy: 0.7169 - lr: 6.2500e-05\n",
            "Epoch 100/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8290 - accuracy: 0.7191 - lr: 6.2500e-05\n",
            "Epoch 101/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.8322 - accuracy: 0.7167\n",
            "Epoch 00101: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.8322 - accuracy: 0.7168 - lr: 6.2500e-05\n",
            "Epoch 102/1000\n",
            "781/781 [==============================] - 32s 40ms/step - loss: 0.8355 - accuracy: 0.7142 - lr: 3.1250e-05\n",
            "Epoch 103/1000\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.8305 - accuracy: 0.7165 - lr: 3.1250e-05\n",
            "Epoch 104/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8254 - accuracy: 0.7181 - lr: 3.1250e-05\n",
            "Epoch 105/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8334 - accuracy: 0.7166 - lr: 3.1250e-05\n",
            "Epoch 106/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8340 - accuracy: 0.7162 - lr: 3.1250e-05\n",
            "Epoch 107/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8325 - accuracy: 0.7194 - lr: 3.1250e-05\n",
            "Epoch 108/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8276 - accuracy: 0.7198 - lr: 3.1250e-05\n",
            "Epoch 109/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.8294 - accuracy: 0.7183\n",
            "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8294 - accuracy: 0.7183 - lr: 3.1250e-05\n",
            "Epoch 110/1000\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.8344 - accuracy: 0.7163 - lr: 1.5625e-05\n",
            "Epoch 111/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8338 - accuracy: 0.7158 - lr: 1.5625e-05\n",
            "Epoch 112/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8278 - accuracy: 0.7207 - lr: 1.5625e-05\n",
            "Epoch 113/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8358 - accuracy: 0.7150 - lr: 1.5625e-05\n",
            "Epoch 114/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.8320 - accuracy: 0.7158\n",
            "Epoch 00114: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8321 - accuracy: 0.7158 - lr: 1.5625e-05\n",
            "Epoch 115/1000\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8355 - accuracy: 0.7167 - lr: 7.8125e-06\n",
            "Epoch 116/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.8297 - accuracy: 0.7164Restoring model weights from the end of the best epoch.\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.8296 - accuracy: 0.7165 - lr: 7.8125e-06\n",
            "Epoch 00116: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35405097b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f42Ud_vxATl1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb57d112-3705-4fcf-9bb5-87ad1943f743"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 73.750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxT95IAGlaN_"
      },
      "source": [
        "# Model 8: final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiIQV9D1AV8Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e60b8ec3-10ec-453d-998e-05d560a01bce"
      },
      "source": [
        "weight_decay = 1e-4\n",
        "L2 = R.l2(weight_decay)\n",
        "\n",
        "model = M.Sequential([\n",
        "    L.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2, input_shape=x_train.shape[1:]),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n",
        "    L.Dropout(0.2), \n",
        "\n",
        "    L.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n",
        "    L.Dropout(0.3), \n",
        "\n",
        "    L.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "             kernel_regularizer=L2),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n",
        "    L.Dropout(0.4), \n",
        "\n",
        "    L.Flatten(),\n",
        "    L.Dense(units=128, activation='relu'), \n",
        "    L.BatchNormalization(),\n",
        "    L.Dropout(0.2),\n",
        "    L.Dense(units=128, activation='relu'), \n",
        "    L.BatchNormalization(),\n",
        "    L.Dropout(0.3),\n",
        "    L.Dense(units=128, activation='relu'), \n",
        "    L.BatchNormalization(),\n",
        "    L.Dropout(0.4),\n",
        "    L.Dense(units=128, activation='relu'), \n",
        "    L.BatchNormalization(),\n",
        "    L.Dropout(0.5),\n",
        "    L.Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "opt = O.RMSprop(lr=0.001, decay=1e-6)\n",
        "model.compile(\n",
        "    optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_49 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_50 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "conv2d_65 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_51 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               524416    \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_54 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_55 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,726,282\n",
            "Trainable params: 1,723,466\n",
            "Non-trainable params: 2,816\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxNJseXNbg2Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0123e70b-e2cc-4410-a91f-786c200eab21"
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "model.fit(\n",
        "    train_generator, \n",
        "    steps_per_epoch=X_train.shape[0]//BATCH_SIZE, \n",
        "    epochs=EPOCHS,  \n",
        "    callbacks=[reduce_learning_rate, early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 2.0355 - accuracy: 0.3292 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 1.3823 - accuracy: 0.5499 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 1.1861 - accuracy: 0.6346 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 1.0875 - accuracy: 0.6815 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 1.0242 - accuracy: 0.7167 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.9888 - accuracy: 0.7343 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.9475 - accuracy: 0.7549 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.9176 - accuracy: 0.7682 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.9099 - accuracy: 0.7760 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.8939 - accuracy: 0.7856 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.8830 - accuracy: 0.7904 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.8675 - accuracy: 0.7999 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.8598 - accuracy: 0.8026 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.8478 - accuracy: 0.8088 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.8472 - accuracy: 0.8101 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.8363 - accuracy: 0.8161 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.8265 - accuracy: 0.8196 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.8227 - accuracy: 0.8225 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.8152 - accuracy: 0.8260 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.8107 - accuracy: 0.8265 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.8082 - accuracy: 0.8269 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.8003 - accuracy: 0.8326 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7992 - accuracy: 0.8329 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.7994 - accuracy: 0.8323 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7930 - accuracy: 0.8358 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.7822 - accuracy: 0.8381 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.7778 - accuracy: 0.8398 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7796 - accuracy: 0.8404 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7812 - accuracy: 0.8394 - lr: 0.0010\n",
            "Epoch 30/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7776 - accuracy: 0.8423 - lr: 0.0010\n",
            "Epoch 31/1000\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.7685 - accuracy: 0.8455 - lr: 0.0010\n",
            "Epoch 32/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7712 - accuracy: 0.8433 - lr: 0.0010\n",
            "Epoch 33/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7710 - accuracy: 0.8460 - lr: 0.0010\n",
            "Epoch 34/1000\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.7565 - accuracy: 0.8478 - lr: 0.0010\n",
            "Epoch 35/1000\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.7614 - accuracy: 0.8466 - lr: 0.0010\n",
            "Epoch 36/1000\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.7551 - accuracy: 0.8494 - lr: 0.0010\n",
            "Epoch 37/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7489 - accuracy: 0.8510 - lr: 0.0010\n",
            "Epoch 38/1000\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.7529 - accuracy: 0.8494 - lr: 0.0010\n",
            "Epoch 39/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7497 - accuracy: 0.8507 - lr: 0.0010\n",
            "Epoch 40/1000\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.7536 - accuracy: 0.8492 - lr: 0.0010\n",
            "Epoch 41/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7446 - accuracy: 0.8538 - lr: 0.0010\n",
            "Epoch 42/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7375 - accuracy: 0.8547 - lr: 0.0010\n",
            "Epoch 43/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7483 - accuracy: 0.8517 - lr: 0.0010\n",
            "Epoch 44/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7360 - accuracy: 0.8541 - lr: 0.0010\n",
            "Epoch 45/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7343 - accuracy: 0.8557 - lr: 0.0010\n",
            "Epoch 46/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7299 - accuracy: 0.8555 - lr: 0.0010\n",
            "Epoch 47/1000\n",
            "781/781 [==============================] - 36s 45ms/step - loss: 0.7344 - accuracy: 0.8560 - lr: 0.0010\n",
            "Epoch 48/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7354 - accuracy: 0.8563 - lr: 0.0010\n",
            "Epoch 49/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7304 - accuracy: 0.8562 - lr: 0.0010\n",
            "Epoch 50/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7316 - accuracy: 0.8588 - lr: 0.0010\n",
            "Epoch 51/1000\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.7289 - accuracy: 0.8578 - lr: 0.0010\n",
            "Epoch 52/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7310 - accuracy: 0.8574 - lr: 0.0010\n",
            "Epoch 53/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7212 - accuracy: 0.8616 - lr: 0.0010\n",
            "Epoch 54/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7194 - accuracy: 0.8589 - lr: 0.0010\n",
            "Epoch 55/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7211 - accuracy: 0.8603 - lr: 0.0010\n",
            "Epoch 56/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7171 - accuracy: 0.8593 - lr: 0.0010\n",
            "Epoch 57/1000\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.7142 - accuracy: 0.8628 - lr: 0.0010\n",
            "Epoch 58/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7218 - accuracy: 0.8590 - lr: 0.0010\n",
            "Epoch 59/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.7108 - accuracy: 0.8616 - lr: 0.0010\n",
            "Epoch 60/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7107 - accuracy: 0.8619 - lr: 0.0010\n",
            "Epoch 61/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7092 - accuracy: 0.8633 - lr: 0.0010\n",
            "Epoch 62/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7034 - accuracy: 0.8638 - lr: 0.0010\n",
            "Epoch 63/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.7088 - accuracy: 0.8626 - lr: 0.0010\n",
            "Epoch 64/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7025 - accuracy: 0.8647 - lr: 0.0010\n",
            "Epoch 65/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7023 - accuracy: 0.8648 - lr: 0.0010\n",
            "Epoch 66/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7092 - accuracy: 0.8651 - lr: 0.0010\n",
            "Epoch 67/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.7016 - accuracy: 0.8660 - lr: 0.0010\n",
            "Epoch 68/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6974 - accuracy: 0.8658 - lr: 0.0010\n",
            "Epoch 69/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.7046 - accuracy: 0.8641 - lr: 0.0010\n",
            "Epoch 70/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.6986 - accuracy: 0.8666 - lr: 0.0010\n",
            "Epoch 71/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.6933 - accuracy: 0.8660 - lr: 0.0010\n",
            "Epoch 72/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.6948 - accuracy: 0.8669 - lr: 0.0010\n",
            "Epoch 73/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.6996 - accuracy: 0.8658 - lr: 0.0010\n",
            "Epoch 74/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.6950 - accuracy: 0.8680 - lr: 0.0010\n",
            "Epoch 75/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.6957 - accuracy: 0.8679 - lr: 0.0010\n",
            "Epoch 76/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.7001 - accuracy: 0.8640\n",
            "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.7000 - accuracy: 0.8640 - lr: 0.0010\n",
            "Epoch 77/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.6371 - accuracy: 0.8829 - lr: 5.0000e-04\n",
            "Epoch 78/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.6082 - accuracy: 0.8891 - lr: 5.0000e-04\n",
            "Epoch 79/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.5900 - accuracy: 0.8920 - lr: 5.0000e-04\n",
            "Epoch 80/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5713 - accuracy: 0.8940 - lr: 5.0000e-04\n",
            "Epoch 81/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5697 - accuracy: 0.8951 - lr: 5.0000e-04\n",
            "Epoch 82/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.5548 - accuracy: 0.8964 - lr: 5.0000e-04\n",
            "Epoch 83/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5492 - accuracy: 0.8984 - lr: 5.0000e-04\n",
            "Epoch 84/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.5468 - accuracy: 0.8988 - lr: 5.0000e-04\n",
            "Epoch 85/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5362 - accuracy: 0.8999 - lr: 5.0000e-04\n",
            "Epoch 86/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5352 - accuracy: 0.8992 - lr: 5.0000e-04\n",
            "Epoch 87/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5381 - accuracy: 0.8964 - lr: 5.0000e-04\n",
            "Epoch 88/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.5279 - accuracy: 0.9011 - lr: 5.0000e-04\n",
            "Epoch 89/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.5312 - accuracy: 0.8978 - lr: 5.0000e-04\n",
            "Epoch 90/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.5249 - accuracy: 0.8996 - lr: 5.0000e-04\n",
            "Epoch 91/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.5253 - accuracy: 0.8981 - lr: 5.0000e-04\n",
            "Epoch 92/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5215 - accuracy: 0.9011 - lr: 5.0000e-04\n",
            "Epoch 93/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5140 - accuracy: 0.9020 - lr: 5.0000e-04\n",
            "Epoch 94/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5162 - accuracy: 0.9007 - lr: 5.0000e-04\n",
            "Epoch 95/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5158 - accuracy: 0.9015 - lr: 5.0000e-04\n",
            "Epoch 96/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5207 - accuracy: 0.8974 - lr: 5.0000e-04\n",
            "Epoch 97/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.5109 - accuracy: 0.9024 - lr: 5.0000e-04\n",
            "Epoch 98/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4999 - accuracy: 0.9050 - lr: 5.0000e-04\n",
            "Epoch 99/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5036 - accuracy: 0.9030 - lr: 5.0000e-04\n",
            "Epoch 100/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5060 - accuracy: 0.9011 - lr: 5.0000e-04\n",
            "Epoch 101/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5068 - accuracy: 0.9017 - lr: 5.0000e-04\n",
            "Epoch 102/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.5035 - accuracy: 0.9036 - lr: 5.0000e-04\n",
            "Epoch 103/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.5016 - accuracy: 0.9030\n",
            "Epoch 00103: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.5016 - accuracy: 0.9029 - lr: 5.0000e-04\n",
            "Epoch 104/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4692 - accuracy: 0.9128 - lr: 2.5000e-04\n",
            "Epoch 105/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4472 - accuracy: 0.9186 - lr: 2.5000e-04\n",
            "Epoch 106/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4490 - accuracy: 0.9169 - lr: 2.5000e-04\n",
            "Epoch 107/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4384 - accuracy: 0.9197 - lr: 2.5000e-04\n",
            "Epoch 108/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.4350 - accuracy: 0.9193 - lr: 2.5000e-04\n",
            "Epoch 109/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4324 - accuracy: 0.9191 - lr: 2.5000e-04\n",
            "Epoch 110/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.4274 - accuracy: 0.9222 - lr: 2.5000e-04\n",
            "Epoch 111/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4244 - accuracy: 0.9225 - lr: 2.5000e-04\n",
            "Epoch 112/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.4172 - accuracy: 0.9248 - lr: 2.5000e-04\n",
            "Epoch 113/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4235 - accuracy: 0.9211 - lr: 2.5000e-04\n",
            "Epoch 114/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4067 - accuracy: 0.9255 - lr: 2.5000e-04\n",
            "Epoch 115/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4152 - accuracy: 0.9233 - lr: 2.5000e-04\n",
            "Epoch 116/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4094 - accuracy: 0.9234 - lr: 2.5000e-04\n",
            "Epoch 117/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4068 - accuracy: 0.9252 - lr: 2.5000e-04\n",
            "Epoch 118/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3965 - accuracy: 0.9285 - lr: 2.5000e-04\n",
            "Epoch 119/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3983 - accuracy: 0.9255 - lr: 2.5000e-04\n",
            "Epoch 120/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.4010 - accuracy: 0.9250 - lr: 2.5000e-04\n",
            "Epoch 121/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.3997 - accuracy: 0.9250 - lr: 2.5000e-04\n",
            "Epoch 122/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3927 - accuracy: 0.9277 - lr: 2.5000e-04\n",
            "Epoch 123/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3969 - accuracy: 0.9258 - lr: 2.5000e-04\n",
            "Epoch 124/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3853 - accuracy: 0.9292 - lr: 2.5000e-04\n",
            "Epoch 125/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3910 - accuracy: 0.9274 - lr: 2.5000e-04\n",
            "Epoch 126/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3866 - accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 127/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3859 - accuracy: 0.9273 - lr: 2.5000e-04\n",
            "Epoch 128/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3890 - accuracy: 0.9270 - lr: 2.5000e-04\n",
            "Epoch 129/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3798 - accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 130/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3852 - accuracy: 0.9289 - lr: 2.5000e-04\n",
            "Epoch 131/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3792 - accuracy: 0.9296 - lr: 2.5000e-04\n",
            "Epoch 132/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3801 - accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 133/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3838 - accuracy: 0.9264 - lr: 2.5000e-04\n",
            "Epoch 134/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3728 - accuracy: 0.9304 - lr: 2.5000e-04\n",
            "Epoch 135/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3780 - accuracy: 0.9283 - lr: 2.5000e-04\n",
            "Epoch 136/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3712 - accuracy: 0.9312 - lr: 2.5000e-04\n",
            "Epoch 137/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3688 - accuracy: 0.9310 - lr: 2.5000e-04\n",
            "Epoch 138/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3728 - accuracy: 0.9296 - lr: 2.5000e-04\n",
            "Epoch 139/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3710 - accuracy: 0.9302 - lr: 2.5000e-04\n",
            "Epoch 140/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3677 - accuracy: 0.9315 - lr: 2.5000e-04\n",
            "Epoch 141/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3731 - accuracy: 0.9291 - lr: 2.5000e-04\n",
            "Epoch 142/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3728 - accuracy: 0.9302 - lr: 2.5000e-04\n",
            "Epoch 143/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3680 - accuracy: 0.9324 - lr: 2.5000e-04\n",
            "Epoch 144/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3675 - accuracy: 0.9306 - lr: 2.5000e-04\n",
            "Epoch 145/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3710 - accuracy: 0.9304 - lr: 2.5000e-04\n",
            "Epoch 146/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3726 - accuracy: 0.9295 - lr: 2.5000e-04\n",
            "Epoch 147/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3640 - accuracy: 0.9318 - lr: 2.5000e-04\n",
            "Epoch 148/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3670 - accuracy: 0.9299 - lr: 2.5000e-04\n",
            "Epoch 149/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3656 - accuracy: 0.9314 - lr: 2.5000e-04\n",
            "Epoch 150/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3679 - accuracy: 0.9296 - lr: 2.5000e-04\n",
            "Epoch 151/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3622 - accuracy: 0.9327 - lr: 2.5000e-04\n",
            "Epoch 152/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3630 - accuracy: 0.9313 - lr: 2.5000e-04\n",
            "Epoch 153/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3600 - accuracy: 0.9315 - lr: 2.5000e-04\n",
            "Epoch 154/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3597 - accuracy: 0.9313 - lr: 2.5000e-04\n",
            "Epoch 155/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3633 - accuracy: 0.9308 - lr: 2.5000e-04\n",
            "Epoch 156/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3630 - accuracy: 0.9308 - lr: 2.5000e-04\n",
            "Epoch 157/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3632 - accuracy: 0.9314 - lr: 2.5000e-04\n",
            "Epoch 158/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3574 - accuracy: 0.9331 - lr: 2.5000e-04\n",
            "Epoch 159/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3588 - accuracy: 0.9323 - lr: 2.5000e-04\n",
            "Epoch 160/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3552 - accuracy: 0.9336 - lr: 2.5000e-04\n",
            "Epoch 161/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3566 - accuracy: 0.9329 - lr: 2.5000e-04\n",
            "Epoch 162/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.3505 - accuracy: 0.9342 - lr: 2.5000e-04\n",
            "Epoch 163/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3517 - accuracy: 0.9327 - lr: 2.5000e-04\n",
            "Epoch 164/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3511 - accuracy: 0.9341 - lr: 2.5000e-04\n",
            "Epoch 165/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3469 - accuracy: 0.9357 - lr: 2.5000e-04\n",
            "Epoch 166/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3553 - accuracy: 0.9330 - lr: 2.5000e-04\n",
            "Epoch 167/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3548 - accuracy: 0.9321 - lr: 2.5000e-04\n",
            "Epoch 168/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3532 - accuracy: 0.9320 - lr: 2.5000e-04\n",
            "Epoch 169/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.3513 - accuracy: 0.9343 - lr: 2.5000e-04\n",
            "Epoch 170/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.9322\n",
            "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.3566 - accuracy: 0.9322 - lr: 2.5000e-04\n",
            "Epoch 171/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3335 - accuracy: 0.9389 - lr: 1.2500e-04\n",
            "Epoch 172/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3238 - accuracy: 0.9427 - lr: 1.2500e-04\n",
            "Epoch 173/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3231 - accuracy: 0.9431 - lr: 1.2500e-04\n",
            "Epoch 174/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3172 - accuracy: 0.9431 - lr: 1.2500e-04\n",
            "Epoch 175/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3134 - accuracy: 0.9452 - lr: 1.2500e-04\n",
            "Epoch 176/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.3136 - accuracy: 0.9443 - lr: 1.2500e-04\n",
            "Epoch 177/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3089 - accuracy: 0.9452 - lr: 1.2500e-04\n",
            "Epoch 178/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3142 - accuracy: 0.9438 - lr: 1.2500e-04\n",
            "Epoch 179/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3038 - accuracy: 0.9465 - lr: 1.2500e-04\n",
            "Epoch 180/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3048 - accuracy: 0.9471 - lr: 1.2500e-04\n",
            "Epoch 181/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.3043 - accuracy: 0.9467 - lr: 1.2500e-04\n",
            "Epoch 182/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3041 - accuracy: 0.9463 - lr: 1.2500e-04\n",
            "Epoch 183/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3024 - accuracy: 0.9469 - lr: 1.2500e-04\n",
            "Epoch 184/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2979 - accuracy: 0.9470 - lr: 1.2500e-04\n",
            "Epoch 185/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3049 - accuracy: 0.9455 - lr: 1.2500e-04\n",
            "Epoch 186/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.3019 - accuracy: 0.9470 - lr: 1.2500e-04\n",
            "Epoch 187/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2961 - accuracy: 0.9468 - lr: 1.2500e-04\n",
            "Epoch 188/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2982 - accuracy: 0.9472 - lr: 1.2500e-04\n",
            "Epoch 189/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2940 - accuracy: 0.9483 - lr: 1.2500e-04\n",
            "Epoch 190/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2991 - accuracy: 0.9463 - lr: 1.2500e-04\n",
            "Epoch 191/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2942 - accuracy: 0.9470 - lr: 1.2500e-04\n",
            "Epoch 192/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2928 - accuracy: 0.9478 - lr: 1.2500e-04\n",
            "Epoch 193/1000\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2886 - accuracy: 0.9495 - lr: 1.2500e-04\n",
            "Epoch 194/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2924 - accuracy: 0.9486 - lr: 1.2500e-04\n",
            "Epoch 195/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2924 - accuracy: 0.9474 - lr: 1.2500e-04\n",
            "Epoch 196/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2901 - accuracy: 0.9480 - lr: 1.2500e-04\n",
            "Epoch 197/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2845 - accuracy: 0.9497 - lr: 1.2500e-04\n",
            "Epoch 198/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2873 - accuracy: 0.9484 - lr: 1.2500e-04\n",
            "Epoch 199/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2878 - accuracy: 0.9482 - lr: 1.2500e-04\n",
            "Epoch 200/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2876 - accuracy: 0.9487 - lr: 1.2500e-04\n",
            "Epoch 201/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2852 - accuracy: 0.9492 - lr: 1.2500e-04\n",
            "Epoch 202/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9478\n",
            "Epoch 00202: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2878 - accuracy: 0.9478 - lr: 1.2500e-04\n",
            "Epoch 203/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2744 - accuracy: 0.9523 - lr: 6.2500e-05\n",
            "Epoch 204/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2734 - accuracy: 0.9530 - lr: 6.2500e-05\n",
            "Epoch 205/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2653 - accuracy: 0.9547 - lr: 6.2500e-05\n",
            "Epoch 206/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2690 - accuracy: 0.9531 - lr: 6.2500e-05\n",
            "Epoch 207/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2671 - accuracy: 0.9537 - lr: 6.2500e-05\n",
            "Epoch 208/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2643 - accuracy: 0.9548 - lr: 6.2500e-05\n",
            "Epoch 209/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2642 - accuracy: 0.9546 - lr: 6.2500e-05\n",
            "Epoch 210/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2607 - accuracy: 0.9569 - lr: 6.2500e-05\n",
            "Epoch 211/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2590 - accuracy: 0.9558 - lr: 6.2500e-05\n",
            "Epoch 212/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2616 - accuracy: 0.9559 - lr: 6.2500e-05\n",
            "Epoch 213/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2576 - accuracy: 0.9565 - lr: 6.2500e-05\n",
            "Epoch 214/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2580 - accuracy: 0.9569 - lr: 6.2500e-05\n",
            "Epoch 215/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2552 - accuracy: 0.9575 - lr: 6.2500e-05\n",
            "Epoch 216/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2577 - accuracy: 0.9560 - lr: 6.2500e-05\n",
            "Epoch 217/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2608 - accuracy: 0.9557 - lr: 6.2500e-05\n",
            "Epoch 218/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2526 - accuracy: 0.9574 - lr: 6.2500e-05\n",
            "Epoch 219/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2572 - accuracy: 0.9555 - lr: 6.2500e-05\n",
            "Epoch 220/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2502 - accuracy: 0.9582 - lr: 6.2500e-05\n",
            "Epoch 221/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2550 - accuracy: 0.9568 - lr: 6.2500e-05\n",
            "Epoch 222/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2537 - accuracy: 0.9577 - lr: 6.2500e-05\n",
            "Epoch 223/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2585 - accuracy: 0.9563 - lr: 6.2500e-05\n",
            "Epoch 224/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2533 - accuracy: 0.9567 - lr: 6.2500e-05\n",
            "Epoch 225/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2496 - accuracy: 0.9578 - lr: 6.2500e-05\n",
            "Epoch 226/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2527 - accuracy: 0.9578 - lr: 6.2500e-05\n",
            "Epoch 227/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2531 - accuracy: 0.9575 - lr: 6.2500e-05\n",
            "Epoch 228/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2461 - accuracy: 0.9577 - lr: 6.2500e-05\n",
            "Epoch 229/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2500 - accuracy: 0.9577 - lr: 6.2500e-05\n",
            "Epoch 230/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2493 - accuracy: 0.9584 - lr: 6.2500e-05\n",
            "Epoch 231/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2505 - accuracy: 0.9580 - lr: 6.2500e-05\n",
            "Epoch 232/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2420 - accuracy: 0.9602 - lr: 6.2500e-05\n",
            "Epoch 233/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2497 - accuracy: 0.9582 - lr: 6.2500e-05\n",
            "Epoch 234/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2484 - accuracy: 0.9570 - lr: 6.2500e-05\n",
            "Epoch 235/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2422 - accuracy: 0.9599 - lr: 6.2500e-05\n",
            "Epoch 236/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2467 - accuracy: 0.9585 - lr: 6.2500e-05\n",
            "Epoch 237/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.9599\n",
            "Epoch 00237: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2430 - accuracy: 0.9599 - lr: 6.2500e-05\n",
            "Epoch 238/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2446 - accuracy: 0.9586 - lr: 3.1250e-05\n",
            "Epoch 239/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2354 - accuracy: 0.9612 - lr: 3.1250e-05\n",
            "Epoch 240/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2334 - accuracy: 0.9620 - lr: 3.1250e-05\n",
            "Epoch 241/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2360 - accuracy: 0.9605 - lr: 3.1250e-05\n",
            "Epoch 242/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2362 - accuracy: 0.9616 - lr: 3.1250e-05\n",
            "Epoch 243/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2335 - accuracy: 0.9615 - lr: 3.1250e-05\n",
            "Epoch 244/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2372 - accuracy: 0.9608 - lr: 3.1250e-05\n",
            "Epoch 245/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2316 - accuracy: 0.9627 - lr: 3.1250e-05\n",
            "Epoch 246/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2330 - accuracy: 0.9616 - lr: 3.1250e-05\n",
            "Epoch 247/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2317 - accuracy: 0.9623 - lr: 3.1250e-05\n",
            "Epoch 248/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2384 - accuracy: 0.9607 - lr: 3.1250e-05\n",
            "Epoch 249/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2262 - accuracy: 0.9633 - lr: 3.1250e-05\n",
            "Epoch 250/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2318 - accuracy: 0.9626 - lr: 3.1250e-05\n",
            "Epoch 251/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2348 - accuracy: 0.9610 - lr: 3.1250e-05\n",
            "Epoch 252/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2293 - accuracy: 0.9623 - lr: 3.1250e-05\n",
            "Epoch 253/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2251 - accuracy: 0.9640 - lr: 3.1250e-05\n",
            "Epoch 254/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2271 - accuracy: 0.9624 - lr: 3.1250e-05\n",
            "Epoch 255/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2255 - accuracy: 0.9640 - lr: 3.1250e-05\n",
            "Epoch 256/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2273 - accuracy: 0.9636 - lr: 3.1250e-05\n",
            "Epoch 257/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2304 - accuracy: 0.9620 - lr: 3.1250e-05\n",
            "Epoch 258/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9621\n",
            "Epoch 00258: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2294 - accuracy: 0.9621 - lr: 3.1250e-05\n",
            "Epoch 259/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2283 - accuracy: 0.9621 - lr: 1.5625e-05\n",
            "Epoch 260/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2257 - accuracy: 0.9636 - lr: 1.5625e-05\n",
            "Epoch 261/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2203 - accuracy: 0.9646 - lr: 1.5625e-05\n",
            "Epoch 262/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2265 - accuracy: 0.9639 - lr: 1.5625e-05\n",
            "Epoch 263/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2203 - accuracy: 0.9649 - lr: 1.5625e-05\n",
            "Epoch 264/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2276 - accuracy: 0.9625 - lr: 1.5625e-05\n",
            "Epoch 265/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2251 - accuracy: 0.9634 - lr: 1.5625e-05\n",
            "Epoch 266/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2259 - accuracy: 0.9630 - lr: 1.5625e-05\n",
            "Epoch 267/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2263 - accuracy: 0.9623 - lr: 1.5625e-05\n",
            "Epoch 268/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.9632\n",
            "Epoch 00268: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2262 - accuracy: 0.9632 - lr: 1.5625e-05\n",
            "Epoch 269/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2226 - accuracy: 0.9634 - lr: 7.8125e-06\n",
            "Epoch 270/1000\n",
            "781/781 [==============================] - 38s 49ms/step - loss: 0.2200 - accuracy: 0.9648 - lr: 7.8125e-06\n",
            "Epoch 271/1000\n",
            "781/781 [==============================] - 38s 48ms/step - loss: 0.2192 - accuracy: 0.9651 - lr: 7.8125e-06\n",
            "Epoch 272/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2223 - accuracy: 0.9644 - lr: 7.8125e-06\n",
            "Epoch 273/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2198 - accuracy: 0.9654 - lr: 7.8125e-06\n",
            "Epoch 274/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2190 - accuracy: 0.9651 - lr: 7.8125e-06\n",
            "Epoch 275/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2216 - accuracy: 0.9646 - lr: 7.8125e-06\n",
            "Epoch 276/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2175 - accuracy: 0.9650 - lr: 7.8125e-06\n",
            "Epoch 277/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2148 - accuracy: 0.9660 - lr: 7.8125e-06\n",
            "Epoch 278/1000\n",
            "781/781 [==============================] - 36s 47ms/step - loss: 0.2204 - accuracy: 0.9642 - lr: 7.8125e-06\n",
            "Epoch 279/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2206 - accuracy: 0.9647 - lr: 7.8125e-06\n",
            "Epoch 280/1000\n",
            "781/781 [==============================] - 37s 48ms/step - loss: 0.2204 - accuracy: 0.9646 - lr: 7.8125e-06\n",
            "Epoch 281/1000\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.2219 - accuracy: 0.9639 - lr: 7.8125e-06\n",
            "Epoch 282/1000\n",
            "780/781 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9649\n",
            "Epoch 00282: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2191 - accuracy: 0.9648 - lr: 7.8125e-06\n",
            "Epoch 283/1000\n",
            "781/781 [==============================] - 36s 46ms/step - loss: 0.2235 - accuracy: 0.9633 - lr: 3.9063e-06\n",
            "Epoch 284/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2194 - accuracy: 0.9646 - lr: 3.9063e-06\n",
            "Epoch 285/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2212 - accuracy: 0.9643 - lr: 3.9063e-06\n",
            "Epoch 286/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2181 - accuracy: 0.9643 - lr: 3.9063e-06\n",
            "Epoch 287/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9658\n",
            "Epoch 00287: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2167 - accuracy: 0.9658 - lr: 3.9063e-06\n",
            "Epoch 288/1000\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2154 - accuracy: 0.9657 - lr: 1.9531e-06\n",
            "Epoch 289/1000\n",
            "781/781 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9656Restoring model weights from the end of the best epoch.\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.2177 - accuracy: 0.9656 - lr: 1.9531e-06\n",
            "Epoch 00289: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35bfbdf358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usfs3Dp-bz6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f383a7e9-08bb-4269-e6eb-e69d1b131dd1"
      },
      "source": [
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> 92.560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CZDHHNpb2ok"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}